{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/arminarj/DGCCA-pytorch/blob/master/DGCCA_loss_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9PcxwzgXQODv"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "a=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LCS80-vPAu7n"
   },
   "outputs": [],
   "source": [
    "def GCCA_loss(H_list):\n",
    "    X=torch.stack(H_list).reshape(3,-1)\n",
    "    S = torch.cov(X)\n",
    "    corr = torch.sum(S)\n",
    "    loss = - corr\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qf_XEQTf7FIl"
   },
   "outputs": [],
   "source": [
    "class MlpNet(nn.Module):\n",
    "    def __init__(self, layer_sizes, input_size):\n",
    "        super(MlpNet, self).__init__()\n",
    "        layers = []\n",
    "        layer_sizes = [input_size] + layer_sizes\n",
    "        for l_id in range(len(layer_sizes) - 1):\n",
    "            if l_id == len(layer_sizes) - 2:\n",
    "                layers.append(nn.Sequential(\n",
    "                    nn.Linear(layer_sizes[l_id], layer_sizes[l_id + 1]),\n",
    "                    nn.Sigmoid(), \n",
    "                    nn.BatchNorm1d(num_features=layer_sizes[l_id + 1], affine=False),\n",
    "                    \n",
    "                ))\n",
    "            else:\n",
    "                layers.append(nn.Sequential(\n",
    "                    nn.Linear(layer_sizes[l_id], layer_sizes[l_id + 1]),\n",
    "                    nn.ReLU(),\n",
    "                    # nn.BatchNorm1d(num_features=layer_sizes[l_id + 1], affine=True),\n",
    "                ))\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "class DeepGCCA(nn.Module):\n",
    "    def __init__(self, layer_sizes1, layer_sizes2, input_size1, input_size2, outdim_size, use_all_singular_values, device=torch.device('cpu')):\n",
    "        super(DeepGCCA, self).__init__()\n",
    "        self.model1 = MlpNet(layer_sizes1, input_size1).double()\n",
    "        self.model2 = MlpNet(layer_sizes2, input_size2).double()\n",
    "        self.model3 = MlpNet(layer_sizes2, input_size2).double()\n",
    "\n",
    "    def forward(self, x1, x2, x3):\n",
    "        \"\"\"\n",
    "\n",
    "        x1, x2 are the vectors needs to be make correlated\n",
    "        dim=[batch_size, feats]\n",
    "\n",
    "        \"\"\"\n",
    "        # feature * batch_size\n",
    "        output1 = self.model1(x1)\n",
    "        output2 = self.model2(x2)\n",
    "        output3 = self.model3(x3)\n",
    "\n",
    "        return output1, output2, output3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_synthData_new(N=400, outDir='./', device='cpu',mode=1,F=20):\n",
    "    '''\n",
    "    creating Main paper Synth data,\n",
    "    N : number of data\n",
    "    F$ : number of features in view $ \n",
    "    '''\n",
    "    views  = []\n",
    "    F1 = F\n",
    "    F2 = F  \n",
    "    F3 = F\n",
    "\n",
    "    V1 = np.random.randn(N, F1)\n",
    "    V2 = np.random.randn(N, F2)\n",
    "    V3 = np.random.randn(N, F3)\n",
    "    views.append(V1)\n",
    "    if mode==1:\n",
    "        V2[:,0]=V1[:,0]+V1[:,1]-V2[:,1]\n",
    "        V3[:,0]=V1[:,0]+2*V1[:,1]-V3[:,1]\n",
    "        \n",
    "    if mode==2:\n",
    "        V2[:,0]=np.sin(V1[:,0]+V1[:,1])-V2[:,1]\n",
    "        V3[:,0]=np.sin(V2[:,0]+V2[:,1])-V3[:,1]\n",
    "        \n",
    "    if mode==3:\n",
    "        V2[:,0]=1/(V1[:,0]+V1[:,1])-V2[:,1]\n",
    "        V3[:,0]=1/(V1[:,0]+V1[:,1])-V3[:,1]\n",
    "\n",
    "    views.append(V2) \n",
    "    views.append(V3)\n",
    "\n",
    "    views = [torch.tensor(view).to(device) for view in views]\n",
    "    return views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9kK_5UIV6ofB"
   },
   "outputs": [],
   "source": [
    "lr = 1e-2\n",
    "device = 'cpu'\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# size of the input for view 1 and view 2\n",
    "F=10\n",
    "input_shape1 = F\n",
    "input_shape2 = F\n",
    "input_shape3 = F\n",
    "X=create_synthData_new(mode=2,F=F)\n",
    "X1 = X[0]\n",
    "X2 = X[1]\n",
    "X3 = X[2]\n",
    "\n",
    "\n",
    "outdim_size = 1\n",
    "\n",
    "# number of layers with nodes in each one\n",
    "layer_sizes1 = [128, 128, outdim_size]\n",
    "layer_sizes2 = [128, 128, outdim_size]\n",
    "layer_sizes3 = [128, 128, outdim_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-3.7924, dtype=torch.float64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "X=create_synthData_new(400,mode=3,F=10)\n",
    "X1 = X[0]\n",
    "X2 = X[1]\n",
    "X3 = X[2]\n",
    "x = X1[:,0]+X1[:,1]\n",
    "y = X2[:,0]+X2[:,1]\n",
    "plt.scatter(x,y)\n",
    "X1.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2_ZRoVWWSNIw"
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy as copy\n",
    "\n",
    "model = DeepGCCA(layer_sizes1, layer_sizes2, input_shape1, input_shape2, outdim_size, False, device).double().to(device)\n",
    "lr  = 1e-2\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=0.5)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.1)\n",
    "criterion = GCCA_loss\n",
    "\n",
    "train_loss = []\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(400):\n",
    "    optimizer.zero_grad()\n",
    "    out1, out2, out3 = model(X1, X2, X3)\n",
    "    loss = criterion([out1, out2, out3])\n",
    "    # print(loss)\n",
    "    train_loss.append(copy(loss.data))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-8.6357, dtype=torch.float64, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.9784, 0.9782],\n",
       "        [0.9784, 1.0000, 0.9995],\n",
       "        [0.9782, 0.9995, 1.0000]], dtype=torch.float64,\n",
       "       grad_fn=<AsStridedBackward0>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H_list =[out1, out2, out3]\n",
    "a=torch.stack([out1, out2, out3]).reshape(3,-1)\n",
    "b = torch.cov(a)\n",
    "\n",
    "for i in range(len(b)):\n",
    "    for j in range(len(b[i])):\n",
    "        b[i][j] /= torch.std(H_list[i])*torch.std(H_list[j])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6814, -2.0779, -1.5268],\n",
       "        [-0.1326,  0.5697,  0.5753],\n",
       "        [ 0.8703,  2.0552,  0.3729],\n",
       "        ...,\n",
       "        [ 0.1502,  0.8841, -1.1338],\n",
       "        [ 0.1226, -0.9440,  2.2582],\n",
       "        [ 0.6393, -1.5740,  0.3744]], dtype=torch.float64,\n",
       "       grad_fn=<ReshapeAliasBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([out1, out2, out3]).reshape(3,400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "colab_type": "code",
    "id": "V5zmmffM9nJH",
    "outputId": "ee92626e-7e6f-447b-f95b-fc9b8d5c5325"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "loss_plt = pd.DataFrame(train_loss)\n",
    "loss_plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "dELtbHByC4I7",
    "outputId": "3ac37621-1c8d-4b1f-ab17-4b4574e3c448"
   },
   "outputs": [],
   "source": [
    "criterion([X1, X2, X3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "47uFfJdEDAWj",
    "outputId": "d2e56e6e-f111-4a4a-e340-30b4407aa74f"
   },
   "outputs": [],
   "source": [
    "print(criterion([X1, X1, X1]))\n",
    "print(criterion([X2, X2, X2]))\n",
    "print(criterion([X3, X3, X3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MG9mDDt0DHWC"
   },
   "outputs": [],
   "source": [
    "out1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPsbWc5PBspg2E+fjIXsxWl",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "DGCCA-loss-test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "myconda",
   "language": "python",
   "name": "myconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
